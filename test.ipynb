{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"score\":65.28169994425551,\"vault\":\"Obsidian-科研\",\"path\":\"Area/00-音频/PyRubberband：专门实现time-stretching and pitch-shifting的library.md\",\"basename\":\"PyRubberband：专门实现time-stretching and pitch-shifting的library\",\"foundWords\":[\"pitch-shifting的library\",\"pitch-shifting.\",\"pitch-shifting\",\"pitch\"],\"matches\":[{\"match\":\"pitch-shifting\",\"offset\":256},{\"match\":\"pitch\",\"offset\":311},{\"match\":\"pitch\",\"offset\":625}],\"excerpt\":\"…reakfastquay.com/rubberband/)[^2], is a high quality software library for audio time-stretching and pitch-shifting. It permits you to change the tempo and pitch of an audio stream or recording dynamically and independently of one another.<br>## Example usage<br>```python<br>import soundfile as sf<br>import pyrubberband as pyrb<br>y, sr = sf.read(&quot;myfile.wav&quot;)<br># Play back at double speed<br>y_stretch = pyrb.time_…\"},{\"score\":36.546158033627066,\"vault\":\"Obsidian-科研\",\"path\":\"音频：pitch shift.md\",\"basename\":\"音频：pitch shift\",\"foundWords\":[\"pitch\"],\"matches\":[],\"excerpt\":\"---<br>uid: 20240220094323<br>aliases:<br>cssclasses: academia, wideTable, centerAlign<br>Desc:<br>---<br>#Area/音频/预处理\"},{\"score\":20.539619350295645,\"vault\":\"Obsidian-科研\",\"path\":\"Area/00-音频/WavAugment.md\",\"basename\":\"WavAugment\",\"foundWords\":[\"pitch\"],\"matches\":[{\"match\":\"Pitch\",\"offset\":473},{\"match\":\"pitch\",\"offset\":507},{\"match\":\"Pitch\",\"offset\":1053}],\"excerpt\":\"| Pitch modification    | 说话人     | pitch at [-300, +300]        |<br>| Additive noise        | 通信信道   | [80, 240]Hz audios in [[MUSAN数据集]]       |<br>| Reverberation         | 通信信道   | room-scale at [0, 100]       |<br>| Band-reject filtering | 神经表示   |  max 150Hz      |<br>| Time masking          | 神经表示   | 50m…\"},{\"score\":10.673457101696583,\"vault\":\"Obsidian-科研\",\"path\":\"Inbox/TODO/WaveFake.md\",\"basename\":\"WaveFake\",\"foundWords\":[\"pitch\"],\"matches\":[{\"match\":\"pitch\",\"offset\":2390}],\"excerpt\":\"在韵律学分析上，作者从[[LJSpeech]]中提取了10000个样本，然后计算基础频率（声高，pitch）。从表1可以看到，所有架构的声高都和原始样本很像，但是还是不能完全的拟合。通常来说，所有的模型的声高更低，变化更小。<br>##### 能量<br>![](https://cdn.jsdelivr.net/gh/RedamancyAY/CloudImage@main/img202305091110638.png)<br>图三展示了和原始样本直方图的差异。从图三可以看出，直方图的整体形状相似，但是还是存在明显差异，特别是在高频。<br>## BaseLine<br>ASVspoofchallenge提供了两个baseline模型：[[Gaussian Mixture Model]]和[[RawNet2]…\"},{\"score\":6.264450475064694,\"vault\":\"Obsidian-科研\",\"path\":\"Area/00-音频/Mel Scale.md\",\"basename\":\"Mel Scale\",\"foundWords\":[\"pitch到声音实际频率直接的映射\"],\"matches\":[{\"match\":\"Pitch到声音实际频率直接的映射\",\"offset\":205}],\"excerpt\":\"Mel尺度是建立从人类的听觉感知的频率——Pitch到声音实际频率直接的映射。人耳对于低频声音的分辨率要高于高频的声音。通过把频率转换成美尔尺度，我们的特征能够更好的匹配人类的听觉感知效果。<br>## 公式<br>### 公式1<br>从频率到美尔频率的转换公式[^1]如下：<br>$$<br>M(f)=1125 ln(1+f/700)<br>$$<br>而从Mel频率到频率的转换公式为：<br>$$<br>M^{-1}(m)=700(e^{m/1125-1})<br>$$<br>### 公式2<br>从频率到美尔频率的转换公式[^2]如下：<br>$$<br>f_{\\\\mathrm{mel}}=2595 \\\\cdot \\\\log _{10}\\\\left(1+\\\\frac{f}{700}\\\\right),<br>$$…\"}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the URL you want to retrieve HTML from\n",
    "url = \"http://localhost:51361/search?q=pitch\"\n",
    "\n",
    "# Perform a GET request to retrieve the HTML content\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Print the HTML content\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 65.28169994425551,\n",
       "  'vault': 'Obsidian-科研',\n",
       "  'path': 'Area/00-音频/PyRubberband：专门实现time-stretching and pitch-shifting的library.md',\n",
       "  'basename': 'PyRubberband：专门实现time-stretching and pitch-shifting的library',\n",
       "  'foundWords': ['pitch-shifting的library',\n",
       "   'pitch-shifting.',\n",
       "   'pitch-shifting',\n",
       "   'pitch'],\n",
       "  'matches': [{'match': 'pitch-shifting', 'offset': 256},\n",
       "   {'match': 'pitch', 'offset': 311},\n",
       "   {'match': 'pitch', 'offset': 625}],\n",
       "  'excerpt': '…reakfastquay.com/rubberband/)[^2], is a high quality software library for audio time-stretching and pitch-shifting. It permits you to change the tempo and pitch of an audio stream or recording dynamically and independently of one another.<br>## Example usage<br>```python<br>import soundfile as sf<br>import pyrubberband as pyrb<br>y, sr = sf.read(&quot;myfile.wav&quot;)<br># Play back at double speed<br>y_stretch = pyrb.time_…'},\n",
       " {'score': 36.546158033627066,\n",
       "  'vault': 'Obsidian-科研',\n",
       "  'path': '音频：pitch shift.md',\n",
       "  'basename': '音频：pitch shift',\n",
       "  'foundWords': ['pitch'],\n",
       "  'matches': [],\n",
       "  'excerpt': '---<br>uid: 20240220094323<br>aliases:<br>cssclasses: academia, wideTable, centerAlign<br>Desc:<br>---<br>#Area/音频/预处理'},\n",
       " {'score': 20.539619350295645,\n",
       "  'vault': 'Obsidian-科研',\n",
       "  'path': 'Area/00-音频/WavAugment.md',\n",
       "  'basename': 'WavAugment',\n",
       "  'foundWords': ['pitch'],\n",
       "  'matches': [{'match': 'Pitch', 'offset': 473},\n",
       "   {'match': 'pitch', 'offset': 507},\n",
       "   {'match': 'Pitch', 'offset': 1053}],\n",
       "  'excerpt': '| Pitch modification    | 说话人     | pitch at [-300, +300]        |<br>| Additive noise        | 通信信道   | [80, 240]Hz audios in [[MUSAN数据集]]       |<br>| Reverberation         | 通信信道   | room-scale at [0, 100]       |<br>| Band-reject filtering | 神经表示   |  max 150Hz      |<br>| Time masking          | 神经表示   | 50m…'},\n",
       " {'score': 10.673457101696583,\n",
       "  'vault': 'Obsidian-科研',\n",
       "  'path': 'Inbox/TODO/WaveFake.md',\n",
       "  'basename': 'WaveFake',\n",
       "  'foundWords': ['pitch'],\n",
       "  'matches': [{'match': 'pitch', 'offset': 2390}],\n",
       "  'excerpt': '在韵律学分析上，作者从[[LJSpeech]]中提取了10000个样本，然后计算基础频率（声高，pitch）。从表1可以看到，所有架构的声高都和原始样本很像，但是还是不能完全的拟合。通常来说，所有的模型的声高更低，变化更小。<br>##### 能量<br>![](https://cdn.jsdelivr.net/gh/RedamancyAY/CloudImage@main/img202305091110638.png)<br>图三展示了和原始样本直方图的差异。从图三可以看出，直方图的整体形状相似，但是还是存在明显差异，特别是在高频。<br>## BaseLine<br>ASVspoofchallenge提供了两个baseline模型：[[Gaussian Mixture Model]]和[[RawNet2]…'},\n",
       " {'score': 6.264450475064694,\n",
       "  'vault': 'Obsidian-科研',\n",
       "  'path': 'Area/00-音频/Mel Scale.md',\n",
       "  'basename': 'Mel Scale',\n",
       "  'foundWords': ['pitch到声音实际频率直接的映射'],\n",
       "  'matches': [{'match': 'Pitch到声音实际频率直接的映射', 'offset': 205}],\n",
       "  'excerpt': 'Mel尺度是建立从人类的听觉感知的频率——Pitch到声音实际频率直接的映射。人耳对于低频声音的分辨率要高于高频的声音。通过把频率转换成美尔尺度，我们的特征能够更好的匹配人类的听觉感知效果。<br>## 公式<br>### 公式1<br>从频率到美尔频率的转换公式[^1]如下：<br>$$<br>M(f)=1125 ln(1+f/700)<br>$$<br>而从Mel频率到频率的转换公式为：<br>$$<br>M^{-1}(m)=700(e^{m/1125-1})<br>$$<br>### 公式2<br>从频率到美尔频率的转换公式[^2]如下：<br>$$<br>f_{\\\\mathrm{mel}}=2595 \\\\cdot \\\\log _{10}\\\\left(1+\\\\frac{f}{700}\\\\right),<br>$$…'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = eval(response.text)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode, quote\n",
    "base_url = \"obsidian://open?valut={}&file={}\"\n",
    "params = {\"valut\": \"b17993ad60da8ab8\", \"file\": r'Area/00-音频/Mel Scale.md'}\n",
    "url = base_url + urlencode(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'obsidian://open?valut=b17993ad60da8ab8&file=Area/00-%E9%9F%B3%E9%A2%91/Mel%20Scale.md'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = base_url.format(quote(\"b17993ad60da8ab8\"), quote(r'Area/00-音频/Mel Scale.md'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Area/00-%E9%9F%B3%E9%A2%91/Mel%20Scale.md'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "query = r'Area/00-音频/Mel Scale.md'\n",
    "urllib.parse.quote(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
